{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNiKLm+Kbpt3kUcl2YDHXSY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4HQXD5kYM2QD"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.optim as optim"]},{"cell_type":"code","source":["# nn.Module\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MultivariateLinearRegressionModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.linear = nn.Linear(3, 1)   # 입력 차원: 3, 출력차원: 1\n","\n","  def forward(self, x):     # Hypothesis 계산은 forward() 에서 수행\n","    return self.linear(x)\n","\n","model = MultivariateLinearRegressionModel()"],"metadata":{"id":"cicvUjYT5mZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PyTorch Dataset\n","\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","  def __init__(self):\n","    self.x_data = [[73, 80, 75],\n","                   [93, 88, 93],\n","                   [89, 91, 90],\n","                   [96, 98, 100],\n","                   [73, 66, 70]]\n","    self.y_data = [[152], [185], [180], [196], [142]]\n","\n","  def __len__(self):            # __len__(): 이 데이터셋의 총 데이터 수\n","    return len(self.x_data)\n","\n","  def __getitem__(self, idx):   # __getitem__(): 어떠한 인덱스(idx) 를 받았을 때 그에 상응하는 값(입출력 데이터)을 반환\n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","\n","    return x, y\n","\n","dataset = CustomDataset()"],"metadata":{"id":"ZcE6q2pb2wZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PyTorch DataLoader\n","\n","from torch.utils.data import DataLoader\n","\n","dataloader = DataLoader(\n","    dataset,\n","    batch_size=2,       # 각 minibatch 의 크기, 통상적으로 2의 제곱수로 설정한다.\n","    shuffle=True,       # 매 Epoch 마다 데이터셋을 섞어서, 데이터가 학습되는 순서를 바꾼다.(항상 True로 설정하는 것을 권장)\n",")"],"metadata":{"id":"5mvrx-rq3zSQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Full Code with Dataset and DataLoader\n","\n","optimizer = optim.SGD(model.parameters(), lr = 1e-5)\n","\n","nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):      # minibatch 인덱스와 데이터를 받는다.\n","    x_train, y_train = samples\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost 로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),   # 한 epoch 당 minibatch 의 개수\n","        cost.item()\n","    ))"],"metadata":{"id":"Ohzw3dV_4wA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8kWyMO5w62vC"},"execution_count":null,"outputs":[]}]}